{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24a3e50a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8a781bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\charl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e69f76",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7918bb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    return nltk.word_tokenize(sentence)\n",
    "\n",
    "def stem(word):\n",
    "    stemmer = PorterStemmer()\n",
    "    return stemmer.stem(word=word.lower())\n",
    "\n",
    "def bag_of_words(tokenized_sentence, all_words):\n",
    "    tokenized_sentence = [stem(w) for w in tokenized_sentence]\n",
    "    \n",
    "    bag = np.zeros(len(all_words), dtype=np.float32)\n",
    "    for idx, w in enumerate(all_words):\n",
    "        if w in tokenized_sentence:\n",
    "            bag[idx] = 1.0\n",
    "            \n",
    "    return bag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8ba601",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ff37b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "intents_key = pd.read_csv('intents-key.csv')\n",
    "intents_df = pd.read_csv('intents.csv')\n",
    "df = pd.read_csv('dataset_appended.csv')\n",
    "df = df.rename(columns={'Unnamed: 0': 'id', 'intent': 'tag', 'prompt': 'patterns', 'completion': 'responses'})\n",
    "\n",
    "intents = {'intents': []}\n",
    "tag_list = list(set(df['tag']))\n",
    "for i, tag in enumerate(tag_list):\n",
    "    intents['intents'].append(dict())\n",
    "    intents['intents'][i]['tag'] = tag\n",
    "    intents['intents'][i]['patterns'] = list(df[df['tag']==tag]['patterns'])\n",
    "    intents['intents'][i]['responses'] = list(set(intents_df[intents_df['intent']==tag]['completion']))\n",
    "    intents['intents'][i]['area'] = list(intents_df[intents_df['intent']==tag]['area'])[0]\n",
    "    intents['intents'][i]['context'] = intents_key[intents_key['area']==intents['intents'][i]['area']]['context'].iloc[0]\n",
    "    \n",
    "with open('intents.json', 'w') as f:\n",
    "    json.dump(intents, f) \n",
    "    \n",
    "with open('intents.json', 'r') as f:\n",
    "    intents = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed2a17e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "tags = []\n",
    "Xy = []\n",
    "\n",
    "for intent in intents['intents']:\n",
    "    tag = intent['tag']\n",
    "    tags.append(tag)\n",
    "    for pattern in intent['patterns']:\n",
    "        words = tokenize(pattern)\n",
    "        all_words.extend(words)\n",
    "        Xy.append((words, tag))    \n",
    "        \n",
    "ignore_words = ['?', '!', '.', ',']\n",
    "all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
    "all_words = sorted(set(all_words))\n",
    "tags = sorted(set(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9782c75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4911, 559)\n",
      "(4911,)\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for pattern_sentence, tag in Xy:\n",
    "    bag = bag_of_words(pattern_sentence, all_words)\n",
    "    X_train.append(bag)\n",
    "    \n",
    "    label = tags.index(tag)\n",
    "    y_train.append(label)\n",
    "    \n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be475c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatDataset(Dataset):\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.n_samples = len(X_train)\n",
    "        self.x_data = torch.from_numpy(X_train)\n",
    "        self.y_data = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_data[idx], self.y_data[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "batch_size = 2048\n",
    "    \n",
    "dataset = ChatDataset(X_train, y_train)\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=batch_size, num_workers=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b789646",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l3(out)\n",
    "        return out\n",
    "\n",
    "input_size = len(X_train[0])\n",
    "hidden_size = 8\n",
    "output_size = len(tags)\n",
    "    \n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08dbf373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500, Loss = 2.9340\n",
      "Epoch 100/500, Loss = 1.8812\n",
      "Epoch 150/500, Loss = 0.9954\n",
      "Epoch 200/500, Loss = 0.5663\n",
      "Epoch 250/500, Loss = 0.3648\n",
      "Epoch 300/500, Loss = 0.2655\n",
      "Epoch 350/500, Loss = 0.2375\n",
      "Epoch 400/500, Loss = 0.1808\n",
      "Epoch 450/500, Loss = 0.1486\n",
      "Epoch 500/500, Loss = 0.1471\n",
      "Final loss = 0.1471\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 500\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for words, labels in train_loader:\n",
    "        words, labels = words.to(device), labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(words)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (epoch+1)%50 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss = {loss.item():.4f}\")\n",
    "    \n",
    "print(f\"Final loss = {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a56e8577",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'model_state': model.state_dict(),\n",
    "    'input_size': input_size,\n",
    "    'output_size': output_size,\n",
    "    'hidden_size': hidden_size,\n",
    "    'all_words': all_words,\n",
    "    'tags': tags\n",
    "}\n",
    "\n",
    "torch.save(data, \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2cd78c",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cdbf2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (l1): Linear(in_features=559, out_features=8, bias=True)\n",
       "  (l2): Linear(in_features=8, out_features=8, bias=True)\n",
       "  (l3): Linear(in_features=8, out_features=40, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.load(\"model.pth\")\n",
    "\n",
    "input_size = data['input_size']\n",
    "hidden_size = data['hidden_size']\n",
    "output_size = data['output_size']\n",
    "all_words = data['all_words']\n",
    "tags = data['tags']\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "model.load_state_dict(data['model_state'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa60998c",
   "metadata": {},
   "source": [
    "Context: Charlie is 28 years old. He is 180cm tall.\n",
    "\n",
    "Bot: Hi there I am bot.\n",
    "You: How old is Charlie?\n",
    "Bot:\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "Context: Charlie's favourite colour is red, his favouries band is Bliss.\\n\n",
    "\n",
    "\\nBot: Hi there I am bot.\n",
    "\\nYou: How old is Charlie?\n",
    "\\nBot: Charlie is 28 years old.\n",
    "\\nYou: What is his favourite colour?\n",
    "\\nBot: \n",
    "\n",
    "\n",
    "-----------\n",
    "\n",
    "\"Context: {context}\\n\n",
    "\n",
    "{conversation}\n",
    "\\nBot:\n",
    "\n",
    "\n",
    "# where conversation is last 3 Bot:... You:... responses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b60800d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chazbot: Hello there. I am Chazbot, designed to answers general questions your may have about Charlie! I will do my best to answer any queries, and remember: to end the conversation, enter 'quit'.\n",
      "\n",
      "You: quit\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "use_gpt3 = 1\n",
    "if use_gpt3: import openai\n",
    "\n",
    "bot_name = \"Chazbot\"\n",
    "start_token = f\"\\n{bot_name}:\"\n",
    "restart_token = \"\\nYou:\"\n",
    "greeting = f\"{start_token} Hello there. I am {bot_name}, designed to answers general questions your may have about Charlie! I will do my best to answer any queries, and remember: to end the conversation, enter 'quit'.\"\n",
    "\n",
    "conversation = []\n",
    "\n",
    "print(greeting)\n",
    "conversation.append(greeting)\n",
    "while True:\n",
    "    while True:\n",
    "        sentence = input(f\"{restart_token} \")\n",
    "        if len(sentence) > 80:\n",
    "            print(f\"Your sentence was {len(sentence)} characters. The maximum allowable characters is 80.\")\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    conversation.append(restart_token + \" \" + sentence)\n",
    "    \n",
    "    if sentence.lower() == \"quit\":\n",
    "        break\n",
    "    \n",
    "    sentence = tokenize(sentence)\n",
    "    X = bag_of_words(sentence, all_words)\n",
    "    X = X.reshape(1, X.shape[0])\n",
    "    X = torch.from_numpy(X).to(device)\n",
    "    \n",
    "    output = model(X)\n",
    "    _, predicted = torch.max(output, dim=1)\n",
    "    tag = tags[predicted.item()]\n",
    "    \n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    prob = probs[0][predicted.item()]\n",
    "    \n",
    "    if prob.item() > 0.0: \n",
    "        for intent in intents['intents']:\n",
    "            if tag == intent['tag']:\n",
    "                if use_gpt3:\n",
    "                    \n",
    "                    context = intent['context']\n",
    "                    openai.api_key = \"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\"\n",
    "                    recent_conversation = \"\".join(conversation[-6:])\n",
    "                    prompt=f\"Context: {context}\\n{recent_conversation}{start_token}\"\n",
    "                    response = openai.Completion.create(\n",
    "                        model='text-davinci-002',\n",
    "                        prompt=prompt,\n",
    "                        temperature=0.5,\n",
    "                        max_tokens=256,\n",
    "                        top_p=1,\n",
    "                        best_of=1,\n",
    "                        frequency_penalty=1,\n",
    "                        presence_penalty=0.2,\n",
    "                        stop=[restart_token]\n",
    "                    )\n",
    "                    output = f\"{start_token} {response['choices'][0]['text'].strip()}\"\n",
    "                else:\n",
    "                    output = f\"{start_token} {random.choice(intent['responses'])}\"\n",
    "                print(output)\n",
    "    else:\n",
    "        output = f\"{start_token} I do not understand the question, please rephrase.\"\n",
    "        print(output)\n",
    "        \n",
    "    conversation.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d3f6ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\nChazbot: Hello there. I am Chazbot, designed to answers general questions your may have about Charlie! I will do my best to answer any queries, and remember: to end the conversation, enter 'quit'.\",\n",
       " '\\nYou: quit']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f4767d",
   "metadata": {},
   "source": [
    "### JSONL Conversion and fine-tuning preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "390f33a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_completions = []\n",
    "for i, row, in df.iterrows():\n",
    "    prompts_completions.append({'prompt': row['patterns'], 'completion': row['responses']})\n",
    "\n",
    "with open('prompts_completions.json', 'w') as f:\n",
    "    json.dump(prompts_completions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9f5a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prompts_completions.json', 'r') as f:\n",
    "    prompts_completions = json.load(f)\n",
    "    \n",
    "with open('prompts_completions.jsonl', 'w') as f:\n",
    "    for pair in prompts_completions:\n",
    "        json.dump(pair, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc849803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': 'The writer is closest to Charlie. ->',\n",
       "  'completion': ' The Greatcoats series was written by Sebastian De Castell. END'},\n",
       " {'prompt': \"Which writer is closest to Charlie's heart? ->\",\n",
       "  'completion': \" Sebastian De Castell is the writer closest to Charlie's heart. END\"}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('prompts_completions_prepared.jsonl', 'r') as f:\n",
    "    json_list = list(f)\n",
    "    prompts_completions = [json.loads(json_str) for json_str in json_list]\n",
    "prompts_completions[398:400]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1e18928",
   "metadata": {},
   "source": [
    "### Tuned using:\n",
    "openai -k <API_KEY> api fine_tunes.create -t C:/Users/charl/Documents/Anaconda/3_Projects/chatbot/prompts_completions_prepared.jsonl -m text-davinci-002\n",
    "###\n",
    "openai -k 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 api fine_tunes.follow -i ft-j81QTddfgXzsQqNB8vx56YwF\n",
    "\n",
    "{\"prompt\":\"Summary: <summary of the interaction so far>\\n\\nSpecific information:<for example order details in natural language>\\n\\n###\\n\\nCustomer: <message1>\\nAgent: <response1>\\nCustomer: <message2>\\nAgent:\", \"completion\":\" <response2>\\n\"}\n",
    "\n",
    "{\"prompt\":\"Summary: <summary of the interaction so far>\\n\\nSpecific information:<for example order details in natural language>\\n\\n###\\n\\nCustomer: <message1>\\nAgent: <response1>\\nCustomer: <message2>\\nAgent: <response2>\\nCustomer: <message3>\\nAgent:\", \"completion\":\" <response3>\\n\"}\n",
    "\n",
    "eg.\n",
    "Summary: summary of interaction\n",
    "\n",
    "Specific information: order details etc.\n",
    "\n",
    "###\n",
    "\n",
    "Customer: ...\n",
    "Agent: ...\n",
    "Customer: ...\n",
    "Agent:\n",
    "\n",
    "\n",
    "Future work:\n",
    "Build web-app for website https://www.youtube.com/watch?v=Wv5jlmJs2sU&list=PLLRM7ROnmA9EnQmnfTgUzCfzbbnc-oEbZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8d5eb9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: <context>\n",
      "\n",
      "Chazbot: Hello there. I am Chazbot, designed to answers general questions your may have about Charlie. Please ask away.\n",
      "You: how old\n",
      "Chazbot: Charlie is 28 years old.\n",
      "You: quit\n",
      "Chazbot:\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b50d59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
